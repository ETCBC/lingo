{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heads2TF\n",
    "\n",
    "In this NB, we produce two text-fabric features on the BHSA data using the get_heads method developed in [getting_heads.ipynb](getting_heads.ipynb). See that notebook for a detailed description of the motivation, method, and shortcomings for this data.\n",
    "\n",
    "N.B. this data is experimental and a work in progress!\n",
    "\n",
    "## Production\n",
    "\n",
    "Two features are produced herein:\n",
    "* heads.tf - an edge feature from a phrase(atom) node to its phrase head + its coordinated head words.\n",
    "* prep_obj.tf - an edge feature from a prepositional phrase type to its noun object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n",
    "\n",
    "### Updates\n",
    "\n",
    "#### 23.10.18\n",
    "New export for the updated C version of BHSA data.\n",
    "\n",
    "#### 21.04.18\n",
    "A new function has been added to double check phrase heads. Prepositional phrases whose objects are also prepositions have resulted in some false heads being assigned. This is because prepositional objects receive no subphrase relations in BHSA and appeared to the algorithm as independent. An additional check is required to make sure that a given preposition does not serve as the head of its phrase. The new function, `check_preposition`, looks one word behind a candidate head noun (within the phrase boundaries) and validates only those cases that are not immediately preceded by another preposition.\n",
    "\n",
    "#### 20.04.18\n",
    "In discussion with Stephen Ku, I've decided to apply the `quantifier` algorithm to prepositional objects so that we retrieve the head of the prepositonal object noun phrase rather than a quantifier. For good measure, I will also apply the `attributed` function (see [getting_heads.ipynb](getting_heads.ipynb) for a description of both functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, collections, random\n",
    "from tf.fabric import Fabric\n",
    "from tf.extra.bhsa import Bhsa\n",
    "from heads import get_heads, find_quantified, find_attributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing version  c \n",
      "\n",
      "This is Text-Fabric 6.3.0\n",
      "Api reference : https://dans-labs.github.io/text-fabric/Api/General/\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "114 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.01s B book                 from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s B chapter              from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s B verse                from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.10s B lex                  from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.21s B typ                  from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.12s B pdp                  from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.29s B rela                 from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.82s T mother               from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.08s B function             from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     1.12s T sp                   from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.99s T ls                   from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "  8.36s All features loaded/computed - for details use loadLog()\n",
      "\n",
      "processing heads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s Feature \"otype\" not available in\n",
      "/Users/cody/github/etcbc/lingo/heads/tf/c\n",
      "  0.00s Not all features could be loaded/computed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "exporting TF...\n",
      "   |     1.10s T heads                to /Users/cody/github/etcbc/lingo/heads/tf/c\n",
      "   |     0.14s T prep_obj             to /Users/cody/github/etcbc/lingo/heads/tf/c\n",
      "\n",
      "done with c\n",
      "processing version  2017 \n",
      "\n",
      "This is Text-Fabric 6.3.0\n",
      "Api reference : https://dans-labs.github.io/text-fabric/Api/General/\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "115 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.02s B book                 from /Users/cody/github/etcbc/bhsa/tf/2017\n",
      "   |     0.01s B chapter              from /Users/cody/github/etcbc/bhsa/tf/2017\n",
      "   |     0.01s B verse                from /Users/cody/github/etcbc/bhsa/tf/2017\n",
      "   |     0.21s B typ                  from /Users/cody/github/etcbc/bhsa/tf/2017\n",
      "   |     0.11s B pdp                  from /Users/cody/github/etcbc/bhsa/tf/2017\n",
      "   |     0.22s B rela                 from /Users/cody/github/etcbc/bhsa/tf/2017\n",
      "   |     0.54s B mother               from /Users/cody/github/etcbc/bhsa/tf/2017\n",
      "   |     0.07s B function             from /Users/cody/github/etcbc/bhsa/tf/2017\n",
      "   |     0.14s B lex                  from /Users/cody/github/etcbc/bhsa/tf/2017\n",
      "   |     0.13s B sp                   from /Users/cody/github/etcbc/bhsa/tf/2017\n",
      "   |     0.12s B ls                   from /Users/cody/github/etcbc/bhsa/tf/2017\n",
      "  6.47s All features loaded/computed - for details use loadLog()\n",
      "\n",
      "processing heads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s Feature \"otype\" not available in\n",
      "/Users/cody/github/etcbc/lingo/heads/tf/2017\n",
      "  0.00s Not all features could be loaded/computed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "exporting TF...\n",
      "   |     1.14s T heads                to /Users/cody/github/etcbc/lingo/heads/tf/2017\n",
      "   |     0.12s T prep_obj             to /Users/cody/github/etcbc/lingo/heads/tf/2017\n",
      "\n",
      "done with 2017\n",
      "processing version  2016 \n",
      "\n",
      "This is Text-Fabric 6.3.0\n",
      "Api reference : https://dans-labs.github.io/text-fabric/Api/General/\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "109 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.01s B book                 from /Users/cody/github/etcbc/bhsa/tf/2016\n",
      "   |     0.01s B chapter              from /Users/cody/github/etcbc/bhsa/tf/2016\n",
      "   |     0.00s B verse                from /Users/cody/github/etcbc/bhsa/tf/2016\n",
      "   |     0.03s T voc_lex_utf8         from /Users/cody/github/etcbc/bhsa/tf/2016\n",
      "   |     0.00s M otext                from /Users/cody/github/etcbc/bhsa/tf/2016\n",
      "   |      |     0.74s C __levels__           from otype, oslots, otext\n",
      "   |      |       13s C __order__            from otype, oslots, __levels__\n",
      "   |      |     0.76s C __rank__             from otype, __order__\n",
      "   |      |       13s C __levUp__            from otype, oslots, __rank__\n",
      "   |      |     8.91s C __levDown__          from otype, __levUp__, __rank__\n",
      "   |      |     3.36s C __boundary__         from otype, oslots, __rank__\n",
      "   |     0.00s M otext                from /Users/cody/github/etcbc/bhsa/tf/2016\n",
      "   |      |     0.10s C __sections__         from otype, oslots, otext, __levUp__, __levels__, book, chapter, verse\n",
      "   |     0.16s B typ                  from /Users/cody/github/etcbc/bhsa/tf/2016\n",
      "   |     0.08s B pdp                  from /Users/cody/github/etcbc/bhsa/tf/2016\n",
      "   |     0.15s B rela                 from /Users/cody/github/etcbc/bhsa/tf/2016\n",
      "   |     0.10s B mother               from /Users/cody/github/etcbc/bhsa/tf/2016\n",
      "   |     0.05s B function             from /Users/cody/github/etcbc/bhsa/tf/2016\n",
      "   |     0.11s B lex                  from /Users/cody/github/etcbc/bhsa/tf/2016\n",
      "   |     0.12s B sp                   from /Users/cody/github/etcbc/bhsa/tf/2016\n",
      "   |     0.12s B ls                   from /Users/cody/github/etcbc/bhsa/tf/2016\n",
      "    43s All features loaded/computed - for details use loadLog()\n",
      "\n",
      "processing heads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s Feature \"otype\" not available in\n",
      "/Users/cody/github/etcbc/lingo/heads/tf/2016\n",
      "  0.00s Not all features could be loaded/computed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "exporting TF...\n",
      "   |     1.18s T heads                to /Users/cody/github/etcbc/lingo/heads/tf/2016\n",
      "   |     0.15s T prep_obj             to /Users/cody/github/etcbc/lingo/heads/tf/2016\n",
      "\n",
      "done with 2016\n"
     ]
    }
   ],
   "source": [
    "# export heads.tf & prep_obj.tf for all TF versions\n",
    "for version in ['c', '2017', '2016']:\n",
    "    \n",
    "    print('processing version ', version, '\\n')\n",
    "    \n",
    "    # load Text-Fabric and data\n",
    "    TF = Fabric(locations='~/github/etcbc/bhsa/tf', modules=version)\n",
    "    api = TF.load('''\n",
    "                  book chapter verse\n",
    "                  typ pdp rela mother \n",
    "                  function lex sp ls\n",
    "                  ''')\n",
    "\n",
    "    F, E, T, L = api.F, api.E, api.T, api.L # TF data methods\n",
    "        \n",
    "    # get heads\n",
    "    heads_features = collections.defaultdict(dict)\n",
    "    \n",
    "    print('\\nprocessing heads...')\n",
    "    \n",
    "    for phrase in list(F.otype.s('phrase')) + list(F.otype.s('phrase_atom')):\n",
    "        \n",
    "        heads = get_heads(phrase, api)\n",
    "        \n",
    "        if heads:\n",
    "            heads_features['heads'][phrase] = set(heads)\n",
    "            \n",
    "        # do prep objects\n",
    "        if F.typ.v(phrase) == 'PP' and heads:\n",
    "            for head in heads:\n",
    "                obj = head + 1 if F.pdp.v(head + 1) != 'art' else head + 2\n",
    "                phrase_bounds = L.d(phrase, 'word')\n",
    "                if obj in phrase_bounds:\n",
    "                    obj = find_quantified(obj, api) or find_attributed(obj, api) or obj\n",
    "                    heads_features['prep_obj'][head] = set([obj])\n",
    "        \n",
    "    # export TF data\n",
    "    print('\\nexporting TF...')\n",
    "    meta = {'': {'created_by': 'Cody Kingham',\n",
    "             'coreData': 'BHSA',\n",
    "             'coreVersion': version\n",
    "            },\n",
    "        'heads' : {'source': 'see the notebook at https://github.com/etcbc/lingo/heads',\n",
    "                  'valueType': 'int',\n",
    "                  'edgeValues': False},\n",
    "        'prep_obj': {'source': 'see the notebook at https://github.com/etcbc/lingo/heads',\n",
    "                  'valueType': 'int',\n",
    "                  'edgeValues': False}\n",
    "       }\n",
    "\n",
    "    save_tf = Fabric(locations='~/github/etcbc/lingo/heads/tf', modules=version, silent=True)\n",
    "    save_api = save_tf.load('', silent=True)\n",
    "    save_tf.save(nodeFeatures={}, edgeFeatures=heads_features, metaData=meta)\n",
    "    \n",
    "    print(f'\\ndone with {version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "## prep_obj.tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 6.3.0\n",
      "Api reference : https://dans-labs.github.io/text-fabric/Api/General/\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "116 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.01s B book                 from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s B chapter              from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s B verse                from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.11s B lex                  from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.19s B typ                  from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.11s B pdp                  from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.20s B rela                 from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.48s B mother               from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.07s B function             from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.12s B sp                   from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.12s B ls                   from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     2.45s T heads                from /Users/cody/github/etcbc/lingo/heads/tf/c\n",
      "   |     0.20s T prep_obj             from /Users/cody/github/etcbc/lingo/heads/tf/c\n",
      "  9.18s All features loaded/computed - for details use loadLog()\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Documentation:** <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa\" title=\"provenance of this corpus\">BHSA</a> <a target=\"_blank\" href=\"https://dans-labs.github.io/text-fabric/Writing/Hebrew/\" title=\"Hebrew characters and transcriptions\">Character table</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/0_home.html\" title=\"BHSA feature documentation\">Feature docs</a> <a target=\"_blank\" href=\"https://dans-labs.github.io/text-fabric/Api/Bhsa/\" title=\"BHSA API documentation\">BHSA API</a> <a target=\"_blank\" href=\"https://dans-labs.github.io/text-fabric/Api/General/\" title=\"text-fabric-api\">Text-Fabric API 6.3.0</a> <a target=\"_blank\" href=\"https://dans-labs.github.io/text-fabric/Api/General/#search-templates\" title=\"Search Templates Introduction and Reference\">Search Reference</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<details open><summary><b>Loaded features</b>:</summary>\n",
       "<a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/book@ll.html\" title=\"info\">book@ll</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/book.html\" title=\"info\">book</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/chapter.html\" title=\"info\">chapter</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/function.html\" title=\"info\">function</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/gloss.html\" title=\"info\">gloss</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/label.html\" title=\"info\">label</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/language.html\" title=\"info\">language</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/lex.html\" title=\"info\">lex</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/ls.html\" title=\"info\">ls</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/number.html\" title=\"info\">number</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/otype.html\" title=\"info\">otype</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/pdp.html\" title=\"info\">pdp</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/rela.html\" title=\"info\">rela</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/sp.html\" title=\"info\">sp</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/typ.html\" title=\"info\">typ</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/verse.html\" title=\"info\">verse</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/voc_lex.html\" title=\"info\">voc_lex</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/voc_lex_utf8.html\" title=\"info\">voc_lex_utf8</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/vs.html\" title=\"info\">vs</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/vt.html\" title=\"info\">vt</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/heads.html\" title=\"info\">heads</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/mother.html\" title=\"info\">mother</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/oslots.html\" title=\"info\">oslots</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/prep_obj.html\" title=\"info\">prep_obj</a></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "This notebook online:\n",
       "<a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/lingo/blob/master/heads/Heads2TF.ipynb\">NBViewer</a>\n",
       "<a target=\"_blank\" href=\"https://github.com/etcbc/lingo/blob/master/heads/Heads2TF.ipynb\">GitHub</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src: url('https://github.com/Dans-labs/text-fabric/blob/master/tf/server/static/fonts/SILEOT.ttf?raw=true');\n",
       "  src: url('https://github.com/Dans-labs/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true') format('woff');\n",
       "}\n",
       "</style>\n",
       "\n",
       "<style type=\"text/css\">\n",
       ".verse {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".vl {\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-end;\n",
       "    align-items: flex-end;\n",
       "    direction: ltr;\n",
       "    width: 100%;\n",
       "}\n",
       ".outeritem {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".sentence,.clause,.phrase {\n",
       "    margin-top: -1.2em;\n",
       "    margin-left: 1em;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 0.3em;\n",
       "    border-style: solid;\n",
       "    border-radius: 0.2em;\n",
       "    font-size: small;\n",
       "    display: block;\n",
       "    width: fit-content;\n",
       "    max-width: fit-content;\n",
       "    direction: ltr;\n",
       "}\n",
       ".atoms {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".satom,.catom,.patom {\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    border-radius: 0.3em;\n",
       "    border-style: solid;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".sentence {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".clause {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".phrase {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".satom {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 4px;\n",
       "}\n",
       ".catom {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".patom {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".word {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 1px solid #cccccc;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".lextp {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 2px solid #888888;\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".occs {\n",
       "    font-size: x-small;\n",
       "}\n",
       ".satom.l,.catom.l,.patom.l {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".satom.r,.catom.r,.patom.r {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".satom.L,.catom.L,.patom.L {\n",
       "    border-left-style: none\n",
       "}\n",
       ".satom.R,.catom.R,.patom.R {\n",
       "    border-right-style: none\n",
       "}\n",
       ".tr,.tr a:visited,.tr a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".trb,.trb a:visited,.trb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".h,.h a:visited,.h a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".hb,.hb a:visited,.hb a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".rela,.function,.typ {\n",
       "    font-family: monospace;\n",
       "    font-size: small;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".pdp,.pdp a:visited,.pdp a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".voc_lex {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vs {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vt {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".gloss {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #444444;\n",
       "}\n",
       ".vrs {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: #444444;\n",
       "}\n",
       ".nd {\n",
       "    font-family: monospace;\n",
       "    font-size: x-small;\n",
       "    color: #999999;\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0a6611;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    direction: ltr;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: x-small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".word .features div,.word .features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       "\n",
       ".hl {\n",
       "    background-color: #ffee66;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_locs = ['~/github/etcbc/bhsa/tf',\n",
    "            '~/github/etcbc/lingo/heads/tf']\n",
    "\n",
    "# load Text-Fabric and data\n",
    "TF = Fabric(locations=data_locs, modules='c')\n",
    "\n",
    "api = TF.load('''\n",
    "              book chapter verse\n",
    "              typ pdp rela mother \n",
    "              function lex sp ls\n",
    "              heads prep_obj\n",
    "              ''')\n",
    "\n",
    "F, E, T, L = api.F, api.E, api.T, api.L # TF data methods\n",
    "\n",
    "B = Bhsa(api, name='Heads2TF', version='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prep = []\n",
    "\n",
    "for ph in F.typ.s('PP'):\n",
    "    heads = E.heads.f(ph)\n",
    "    objs = [E.prep_obj.f(prep)[0] for prep in heads\n",
    "               if E.prep_obj.f(prep)]\n",
    "    test_prep.append(tuple(objs))\n",
    "    \n",
    "random.shuffle(test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.show(test_prep[:50]) # uncomment me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what the prepositional object looks like for Genesis 1:21:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example phrase 651768 phrase number 14 in verse\n",
      "אֵ֨ת כָּל־עֹ֤וף כָּנָף֙ \n",
      "\n",
      "Gen 1:21 phrase 14's heads, a preposition:\n",
      "אֵ֨ת \n",
      "\n",
      "Gen 1:21 phrase 14's prepositional object:\n",
      "עֹ֤וף \n"
     ]
    }
   ],
   "source": [
    "gen_121_case = L.d(T.nodeFromSection(('Genesis', 1, 21)), 'phrase')[13]\n",
    "\n",
    "print('example phrase', gen_121_case, 'phrase number 14 in verse')\n",
    "print(T.text(L.d(gen_121_case, 'word')))\n",
    "\n",
    "print('\\nGen 1:21 phrase 14\\'s heads, a preposition:')\n",
    "heads = E.heads.f(gen_121_case)\n",
    "print(T.text(heads))\n",
    "\n",
    "\n",
    "print('\\nGen 1:21 phrase 14\\'s prepositional object:')\n",
    "print(T.text(E.prep_obj.f(heads[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heads.tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = [E.heads.f(ph) for ph in F.otype.s('phrase') if F.typ.v(ph) == 'NP']\n",
    "random.shuffle(heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.show(heads[:50]) # uncomment me"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
